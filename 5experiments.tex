\chapter{Experiments}\label{experiments}

This chapter presents the experimental performed in this Dissertation. The rest of the chapter is organized as follows. First, we will have an overview of the corpora used to perform the experiments. Then we describe the experimental setup used to perform the thematic role assignment task with the Word2Vec-ESN model and the variant proposed in the previous chapter. We also describe the experiments performed for thematic role assignment task.

\section{Corpora and pre-processing}\label{corpora}

This section describes the corpora used to perform experiments with the proposed Word2Vec-ESN language model and its variant for TRA task. Firstly, we will have an overview of the corpora used for TRA task and then we will see about the corpus used to train Word2Vec model.

\subsection{Corpora For TRA Task}

In order to have a fair comparison between the Word2Vec-ESN model and $\theta RARes$ model (described in section \ref{sec:xavier_model}), we used the same coprora\footnote{https://sites.google.com/site/xavierhinaut/downloads} used by Hinaut et al. \cite{xavier:2013:RT, tra:xavier_hri} to perform TRA task with $\theta RARes$ model. Thus, the corpus-373, corpus-462, corpora-90582 containing 373, 462 and 90582 sentences respectively were used to perform the Experiments with the proposed model for TRA task.  

\paragraph{Corus-45:}  Corpus-45 is a small corpus with 45 sentences. This corpus contains the construction in grammatical forms i.e. 'N' and 'V' tokens were used to represent the nouns and verbs, along with the coded meaning of each sentence. The corpus contains construction with different grammatical structures i.e. active, passive, object-relative, subject-relative sentences (see file corpus-45.txt) which are represented in the form:

\begin{enumerate}[noitemsep]
\item the N V the N . \# N1-A1   N2-O1
\item the N was V by the N . \# N1-O1  N2-A1
\end{enumerate}

The coded meaning of the sentences is represented after `$\#$' token. The coded meaning "N1-A1" can be interpreted as: first noun is the agent of first verb. For the object and recipient roles 'O' and 'R' tokens were used repectively.

\paragraph{Corpus-462 and Corpus-90582:} The sentences in corpus-462 and corpus-90582 were generated by Hinaut et al. using a context-free-grammer for English language and used for TRA task \cite{xavier:2013:RT}. Each sentence in these corpora have verbs which takes 1, 2, 3 clause elements. For example, the sentences, 'The man \textit{jump}', 'The boy \textit{cut} an Apple', 'John \textit{gave} the ball to Marie', have verbs with clause elements agent, agent and object, or agent, object and recipient respectively. The sentences in the corpora have a maximum of four nouns and two verbs \cite{xavier:2013:RT}. A maximum of 1 relative clause is present in the sentences; verb in the relative clauses could take 1 or 2 clause elements (i.e., without recipient). For e.g. 'The dog that bit the cat chased the boy'. Both the corpus-462 and corpus-90582 have the constructions in form:

\begin{enumerate}[noitemsep]
\item walk giraffe $<\!o\!>$ AP $<\!/o\!>$ ; the giraffe walk -s . \# ['the', 'X', 'X', '-s', '.']
\item cut beaver fish , kiss fish girl $<\!o\!>$ APO , APO $<\!/o\!>$ ; the beaver cut -s the fish that kiss -s the girl . \# ['the', 'X', 'X', '-s', 'the', 'X', 'that', 'X', '-s', 'the', 'X', '.']
\end{enumerate}

Each construction in the corpus was divided into four parts. The first part describes the meaning of sentence using semantic words (or open class words) in order of predicate, agent, object, recipient. The second part (between '$<\!o\!>$' and '$<\!/o\!>$') describes the order of thematic roles of semantic words as they appear in the raw sentence. The third part (between ';' and '\#') contains the raw sentence with verb inflections (i.e. '-s') and the fourth part is the abstract representation of a sentence with semantic words removed and replace with 'X' \cite{xavier:2013:RT}.

Corpus-90582 have 90582 sentences along with the coded meaning of each sentence. This corpus is redundant; multiple sentences with different grammatical structure but the same coded meaning (see fig. \ref{fig:meaning_realtions}). In total, there were only 2043 distinct coded meanings \cite{xavier:2013:RT}. This corpus also has an additional property that along with complete coded meanings for sentences it also have incomplete meanings. For example, the sentence ``The Ball was given to the Man‚Äù have no \textit{`Agent'}, and thus the meaning of the sentence is ``given(-, ball, man)". The corpus also contains $5268$ pair and $184$ triplets of ambiguous sentences i.e., 10536 and 553 sentences respectively. Thus in total there were $12.24 \%$ (i.e., $ 5268 \times 2 + 184 \times 3 = 11088 $) of ambiguous sentences which have the similar grammatical structure but different coded meaning \cite{xavier:2013:RT}.

\paragraph{Corpus-373:} Apart from the corpus-462 and corpus-90582 which were artificially constructed using the context-free grammar, we also used the corpus-373. Corpus-373 includes the instructions collected from the participants interacting with a humanoid robot (iCub) in a Human-Robot Interaction study of language acquisition conducted by Hinaut et al. \cite{tra:xavier_hri}. In the study, the robot first performs one or two actions by placing the available objects to a location (e.g. left, right, middle) and the participants observes the actions. Then the participants were asked to instruct the robot again to perform the same actions in natural language. Thus the corpus contains 373 complex instructions to perform single or double actions with temporal correlation (see Action Performing task in Hinaut et al. \cite{tra:tra:xavier_hri} for more details). For example, the instruction "Point to the guitar" is a one action command whereas the instruction "Before you put the guitar on the left put the trumpet on the right" is a complex command with double actions, where the second action is specified before the first action. A list of 86 closed class words used to pre-process the data are also provided with this corpus. Also, unlike corpus-462 and corpus-90582 this corpus does not contain verbs inflections. Thus, this data is complex enough to test the learnability and generalization of the proposed models on TRA task.

\paragraph{Pre-processing:} We modified the sentences in this corpus-45 by replacing the token 'N' and 'V' with appropriate nouns and verbs such that the same coded meaning of the sentence is not changed. For example, the construction ``the N V the N" was changed to ``the man pushed the ball". Recall that the corpus-462 and corpus-90582 have sentences where are verbs are represented along with inflections (suffixes ``-s", ``-ed", ``-ing"). We preprocessed these constructions in corpus-462 and corpus-90582, to obtain the raw sentences without verb inflections. Firstly, all the words are lowercased and then the verbs with inflections are replaced by conjugated verbs \footnote{service used to find verb conjugations: \text{http://www.scientificpsychic.com/cgi-bin/verbconj2.pl}}. The verb conjugation to be used depends on the inflection used for the verb. For example, the sentences ``The giraffe walk -s" and ``John eat -ed the apple" has been changed to ``The giraffe walks" and ``John ate the apple" respectively. This preprocessing was done because the distributed word representation captured by word2vec model already captures these syntactic relations which was imposed previously using verb inflection e.g $vector('walks') - vector('walk') \approx vector('talks') - vector('talk')$. 
  
\subsection{Corpus For Training Word2Vec Model}

In this work, To train the word2vec model, we used the Wikipedia corpus\footnote{https://dumps.wikimedia.org/enwiki/latest/} ($\approx$ 14 GB) to obtain the low dimensional distributed embeddings of words. The corpus contains 2,65,8629 unique words. We chose to use Wikipedia data because we needed a general purpose dataset to get the vector representation of words. The Word2Vec model does not give good quality vector representation for words when trained over a small corpus thus a general purpose data set with billions of words is required to have good word embeddings. Thus more words we have the better the vector representation of words. Once the vector representation of words in Wikipedia data is obtained, the model can then be trained further on any our domain specific dataset (corpus-462 and corpus-90582) with more bias toward domain specific dataset (by repetition of dataset during training) to update the previously learned vector representations. 

\section{Experimental Setup}

\subsection{Obtaining Word Embeddings} \label{get_word_embeddings}

Before using the model for TRA task, we need to have the word embeddings. So in order to get the vector representation of words we first trained the Word2Vec model on Wikipedia dataset. For training, the word2vec model with skip-gram negative sampling (see Chapter \ref{basics} for more details) approach was used to obtain the word embeddings as it was claimed to accelarate the training and generates better word vectors which performs better on word analogy task\cite{w2v:mikolov_2013_efficient, w2v:mikolov_2013_distributed}. 

To obtain the word vectors of different dimensions, 6 word2vec models were trained with the hidden layer containing 20, 30, 50, 100, 200, 300 units respectively. Thus each model produce a distributed word embedding corresponding to the size of hidden layer. All the 6 models were trained using same hypermeters. A context window of $\pm 5$ was used. The negative sampling size of 5 was chosen i.e. 5 noise words are chosen randomly from the vocabulary which does not appear in the context of the current input word. As the Wikipedia corpus is huge, it contains some words like "a", "the", "in" etc. which occurs million of times. Thus the frequent words are discarded with the probabily using equation \ref{eqn:subsampling} with a subsampling threshold of $t = 10^{-5}$. We ignored all the words which appear less than $5$ times in the corpus. To update the network weights stochastic gradient descent was used \cite{w2v:parameter_learning, w2v:mikolov_2013_distributed}. The initial learning rate was set to be $\alpha = 0.025$, which drops to $min_alpha = 0.0001$ linearly as training progress. 

The word embeddings obtained from training on Wikipedia dataset are accurate enough to capture the semantic relationship of words for e.g. $vec(Paris) -vec(France) + vec(Germany) \approx vec(Berlin)$. Before training the model on Wikipedia corpus, a vocabulary of words is created and once the vocabulary is created it is not possible to add new words to this vocabulary. However, there is a possibility that when a domain specific corpus (e.g. corpus-462, corpus-373 etc.) is used to further train the Word2Vec model, some of the new words may not be present in previously generated vocabulary. Due to this limitation, it was not possible to get the distributed embeddings of these new words. Thus we needed to update the vocabulary of the model, if the new words are not present in the vocabulary in order to facilitate the online training of Word2Vec model. Unfortunately, neither C++ API \footnote{https://code.google.com/archive/p/word2vec/} nor Gensim python API \cite{w2v:gensim_api} implementation of Word2Vec supports vocabulary update, once created. So, we implemented the online training\footnote{The code is adapted from-  http://rutumulkar.com/blog/2015/word2vec} of word2vec by modifying and extending the Gensim API. The new words that were not present in the existing vocabulary is now added and initialized with some random weights. The model can then be trained in the usual manner to learn the distributed  embeddings of new words. Although now the vocabulary can now be updated in an online manner but the vector embedding of the newly added words has poor quality if its count in the new corpus is less. This can be improved by repetition of new dataset several times before training the model \footnote{Idea discussed on: https://groups.google.com/forum/$\#$!topic/gensim/Z9fr0B88X0w}.

So now when we have an online version of training word2vec model, we extend the word2vec model by resuming the training on the domain specific corpus (corpus-462 and corpus-90582). While updating the model on the new dataset we do not disregard any word irrespective of its count, so that we have vector embeddings of all the words in our domain specific corpora. Once the Word2Vec model is trained, the generated word embeddings was normalized using L-2 norm before using them. On important point to remember while training word2vec model is that if a already trained model has to be trained further on any other corpus, then normalization should not be done, as it is not possible to train the model again with normalized word vectors \cite{w2v:gensim_api}. The trained word2vec model is now ready to be used with Word2Vec-ESN model.

\subsection{ESN reservoir initialization}

The size of the reservoir is one of the important parameters of ESN and is often recommended to use a bigger reservoir that can be computationally afforded provided the appropriate regularization method is used \cite{esn:practical_guide}. The bigger the size of the reservoir, the easier it is for the ESN to learn from the input signal. Thus we chose a reservoir of 1000 (until and unless specified) leaky integrator neurons with \textit{tanh} activation function. The input-to-hidden, hidden-to-hidden weights were randomly and sparsely generated using a normal distribution with mean 0 and variance 1. Thematic role assignment does not use any feedback from the readout layer, we do not use any output-to-hidden weights. The state update equations \ref{eqn:res_update} and \ref{eqn:res_state} thus changes to:

\begin{equation} \label{eqn:res_new_update}
x'(n) =\textit {tanh } ( W^{res}x(n-1) + W^{in}.u(n))
\end{equation}
\begin{equation} \label{eqn:res_new_state}
x(n) =\textit (1-\alpha) x(n-1) + \alpha x'(n)
\end{equation}

To generate the sparse weights a fixed fanout number of $F_{hh} = 10$ and $F_{ih} = 2$ was used i.e. each reservoir neuron was randomly connected to $10$ other reservoir neurons and each input neuron was connected to only $2$ other reservoir neurons. Use of fixed fanout number scales the cost of state update of reservoir linearly with increase in reservoir size \cite{esn:practical_guide}. After weights initialization, there are several parameters which are to be optimized which are task specific. In the next subsection we describe the optimization of reservoir parameters.

\subsection{Learning ESN parameters} \label{grid_search}

Echo state network have several parameters to be optimized for the proposed model to perform efficiently on thematic role assignment task. Some of the parameters like reservoir size, sparsity, distribution of non-zero weights are straightforward \cite{esn:practical_guide}. Whereas other parameters like Spectral Radius (SR), Input Scaling (IS) and Leak Rate (LR) are task dependent and are often tuned by multiple trials. Thus to identify these parameters, we performed a grid search over the parameter space using 5 reservoir instances. As the parameter search space can be really large, a broader grid with wider parameter ranges was first explored to find the optimal grid: grid with low sentence error for Word2Vec-ESN model and high F1-Score for the model variant. The optimal region identified during the broder grid search was then used for the narrow search to identify the optimal parameters \cite{esn:practical_guide}. As both the proposed model and its variant process the sentences differently and have different training objectives, the ESN parameters for both the model and its variant were optimized separately. Also, the Word2Vec-ESN model parameters are optimized separately for sentence continuous learning mode and in sentence final learning mode. Here we describe about parameter optimization for the general case for corpus-462. 

\paragraph{Word2Vec-ESN model:} To optimize the reservoir parameters, corpus-462 was used. To get the optimal paramaters (i.e. parameters producing the lowest sentence error) of Word2Vec-ESN model, the model was trained and tested over a range of parameters using 10-fold cross-validation method; corpus-462 with 462 sentences was randomly split into 10 equally sized subsets (i.e. each subset with $\approx$ 46 sentences). The model was trained on sentences from 9 subsets and then tested on remaining one subset. This process was repeated 10 times such that the model was trained and tested on all the subsets at least once. A reservoir of 1000 neurons and a fixed regularization coefficient, $\beta = 1\mathrm{e}{-6}$ for ridge regression was used. By exploring the parameter space we identified the optimal parameters as $SR = 2.4$, $IS = 2.5$ and $LR = 0.07$ in SCL mode and $SR = 2.2$, $IS = 2.3$ and $LR = 0.13$ in SFL mode.   

\paragraph{Word2Vec-ESN model variant: } For the Word2Vec-ESN model variant, we find the optimal parameters (i.e. parameters producing highest F1-Score) during the grid search using the same corpus-462 and by applying 10-fold cross-validation. Keeping all the parameters i.e. reservoir size and regularization coefficient, identical to Word2Vec-ESN model described above, optimal parameters were identified as $SR = 0.7$ , $IS = 1.15$, $LR = 0.1$. As later in the experiment 2, we will also be testing the performance of the model variant on the sentences transformed to grammatical form (i.e. semantic words replaced with 'SW' token) and using localist word vectors. We also need to find the optimal parameters for this transformed dataset. Keeping all the conditions same, we performed a grid search over parameter space and identified the optimal parameters as $SR = 1.3$, $IS = 1.0$ , $LR = 0.4$. 

\subsection{Input and Ouput Coding}

As specified in chapter \ref{approach}, the Word2Vec-ESN model and its variant process the sentences differently, thus the input and output coding also differs. However, the initialization of reservoir weights remains same both the models. 

\paragraph{Word2Vec-ESN model:}

A raw sentence is presented to the model, where each word in the sentence is processed across time by both word2vec model and ESN. The word2vec model outputs the $E_{v} = 50$ dimension word embedding which is then used as an input for ESN. Thus input layer of ESN has $50$ neurons.

For all the experiments on corpus 45, 462 and 90582 (Experiments 1-5 in next section), an equivalent but topologically modified coded meaning (see section \ref{sec:model_variant}) was used, the readout layer of ESN contains 24 $(4 \times 3 \times 2)$ neurons as the corpus contains sentences, having a maximum of 4 nouns each having 3 possible roles (Agent, Object, and Recipient) with respect to a maximum of 2 verbs. Each neuron in the readout layer thus codes for a role of a noun with respect to a verb.

For Experiment-6, the topologically modified coding was not used. So, the readout layer contains 36 $(6 \times 3 \times 2)$ neurons as there are maximum of 6 semantic words in this corpus and each could have one of the 3 possible thematic roles (Object, Predicate, Location) with respect to maximum of two actions \cite{tra:xavier_hri}. 

Output neuron has an activation 1 if the role is present in the sentence, -1 otherwise. When using corpus-90582 for training the number of neurons in the reservoir were raised to 5000 and also the  readout neurons are increased to 30 $(5 \times 3 \times 2)$ as there was maximum of 5 nouns in the sentences of this corpus. 

\paragraph{Word2Vec-ESN model variant:}

Recall that in Word2Vec-ESN model variant a raw sentence is presented to the model, where each word (argument) along with the verb (Predicate) with respect to which the word is currently processed, is input to the model across time(see section \ref{sec:model_variant}). A sentence is processed as many time as there are verbs in the sentence. The word2vec model firstly takes this argument-predicate pair as an input and outputs a vector of $E_{v} = 2 \times 50$ dimension, which is then used as an input to ESN. Thus input layer thus has $100$ neurons where first $50$ neurons encodes the vector representation of the word and remaining $50$ neurons codes for the verb with respect to which word is being processed. Unlike the model variant-1, the size of readout neurons always remains the same and contains 5 neurons each coding for a role: Predicate (P), Agent (A), Object(O), Recipient (R) and No Role (XX) for both corpus-462 and corpus-90582. Readout neuron of ESN has an activation 1 if the input word-verb (argument-predicate) pair have the corresponding role, -1 otherwise.   

\section{Experiments}

In this section we descibe the experiment performed in this thesis. Untill and unless specified we use all the optimal parameters identified during the grid search for both Word2Vec-ESN model and its variant, described in section \ref{grid_search}. 

\subsection{Experiment-1: Model performance on small corpous}\label{exp-1}

In order to determine the model's capability for predicting thematic roles of the sentences using word2vec embeddings for words, we first used the limited set of sentences i.e. 26 sentences (sentence 15 to 40) from corpus-45. The chosen sentences have distinct surface form and grammatical structure (e.g. active, passive, dative-passive). Using these limited set of sentences we performed the simulations both on Word2Vec-ESN model and its variant. Both the models were first trained and tested on all the sentences to get the training errors and then tested using Leave one Out (LoO) cross-validation method: training on 25 sentences and testing on 1 sentence, such that all the sentences are tested atleast once.
 
For simulation with word2Vec-ESN model a reservoir of 1000 neurons and reservoir parameters, SR=? , IS=?, LR=? was used. Whereas for simulations with model variant a reservoir of 500 neurons with reservoir parameters SR=? , IS=? , LR=?, was used. The parameters for both the model variants were found by exploring the parameter space using LoO cross-validation. This experiments remains a toy demonstration and we will explore the generalization capabilty of the model further with the an extend corpus in experiment 2 and \ref{exp-5}.

\subsection{Experiment-2: Generalization Capabilities} \label{exp-2}

In the experiment \ref{exp-1}, we performed simulations with limited set of constructions. Thus in order to test the generalization capability of the model, an extended corpus of 462 sentences was examined (see corpus-462 in \ref{datasets}). 

\paragraph{Word2Vec-ESN model:}We performed simulations on Word2Vec-ESN model using 10-fold cross validation. A reservoir of size 1000 neurons was used. For this experiment we used the equivalent topologically modified output coding. In order to compare the generalization ability of the Word2Vec-ESN model and $\theta RARes$ model, simulations were performed in both the learning modes i.e. in SCL and SFL mode. The reservoir parameters identified during grid search for both the learning modes were used i.e. $SR = 2.4$, $IS = 2.5$, and $LR = 0.07$ in SCL mode and $SR = 2.2$, $IS = 2.3$ and $LR = 0.13$ SFL mode (see section \ref{grid_search}).

\paragraph{Word2Vec-ESN model variant:} Recall that the Word2Vec-ESN model variant process the sentences diffently from Word2Vec-ESN model (see section \ref{sec:model_variant} in chapter \ref{approach}). Thus in order to compare the effect of processing the raw sentences with distributed word embeddings over the transformed sentence in grammatical form with localist word vectors, simulations were performed on the model variant in two different configurations. Simulations in both the configurations were performed using a 5 reservoir instances of 1000 neurons.

\begin{enumerate}
\setlength{\itemsep}{\smallskipamount}

\item \textbf{Configuration-1: } In this configuration, the model variant process the sentences using the standard functioning of model variant i.e. raw sentences were used and word2vec embeddings generated by Word2Vec unit are input to ESN (see section \ref{sec:model_variant} for more detail). For performing simulations in this configuration, the reservoir parameters  $SR = 0.7$ , $IS = 1.15$, $LR = 0.1$ were used. The parameters are indentified by exploring the parameter space. \label{config-1}

\item \textbf{Configuration-2: } In this configuration, the model variant is used without word2vec unit and only ESN is used for processing the sentence. However, all the functioning remains the same. The input sentences were transformed in grammatical form: all the semantic words in the sentence were replace with 'SW' token, and localist word vectors are input to ESN. For simulation the reservoir parameters $SR = 1.3$, $IS = 1.0$ , $LR = 0.4$ found previously during grid search were used. \label{config-2}

\end{enumerate} 

\subsection{Experiment-3: Effect of Corpus structure} \label{exp-3}

As described previously, that the sentences in the corpus-462 were created based on context-free grammar. Thus the sentences in the corpus contain an inherent grammatical structure. The models thus possibly utilizes the underlying grammatical structure to some extent for learning and generalizing. To test this hypothesis and to demonstrate that the model is not generalizing on any other inconsistent regularity in the corpus, in this experiment, the inherent grammatical structure from the sentences was removed by randomizing the word orders within the sentences \cite{xavier:2013:RT}. Such a test will also help us to have an insight on what the model is actually learning and whether the model is overfitting or not. The situation of overfitting typically occurs when the corpus size is significantly less than the number of trainable parameters \cite{xavier:2013:RT}. In our case with corpus-462, the number of trainable parameters is significantly greater than our corpus size (i.e. 462 sentences). This is thus a possible situation of overfitting.

In this experiment, the corpus-462 with the scrambled sentences (i.e. in absence of any grammatical structure) was presented to Word2Vec-ESN model. Keeping all the conditions and the reservoir parameters same as used in Experiment-2, a 10 fold cross-validation was performed with 5 model instances. The cross-validation errors obtained in the Experiment-2 on the corpus-462 with inherent grammatical structure can then be compared with the cross-validation error obtained while using scrambled corpus. If the model is not overfitting and learning from the grammatical structure then the model should not perform better on the corpus with scrambled sentences (i.e. in absence of grammatical structure). However, in the case of overfitting the generalization effect on the corpus should not vary much both in presence and absence of grammatical structure \cite{xavier:2013:RT}. 

\subsection{Experiment-4: Effect of Reservoir size} \label{exp-4}

The most important hyperparameter which effects the performance of the model is the size of the reservoir (i.e. number of neurons in the reservoir). Addition of neurons in the reservoir is also computationally inexpensive because the read-out weights ($W^{out}$) scales linearly with the number of neurons in the reservoir \cite{esn:learn_gs}. So, in order to determine the effect of reservoir size on the performance of the Word2Vec-ESN model and its variant, the simulations were performed over a range of reservoir size \footnote[1]{Reservoir sizes explored in Word2Vec-ESN model: [90, 291, 493, 695, 896, 1098, 1776, 2882, 3988, 5094]} \footnote[2]{Reservoir sizes explored in model variant: [50, 100, 250, 400, 600, 800, 1050, 1600, 2250, 3320, 3860, 4500]} using 5 instances of the model i.e. reservoir weights of the model were initialized using 5 different random generator seeds). 

\paragraph{Word2Vec-ESN model:} Using the Word2Vec-ESN model, the simulations were performed on a range of reservoir size\footnotemark[1] in both SCL and SFL modes. We used the same optimal reservoir parameters used in the experiment 2 i.e. $SR = 2.4$, $IS = 2.5$ and $LR = 0.07$ in SCL mode and $SR = 2.2$, $IS = 2.3$ and $LR = 0.13$ in SFL mode. 

\paragraph{Word2Vec-ESN model variant: } To see the effect of reservoir size on model variant, simulations were performed on a range of reservoir size\footnotemark[2], in both the configuration-1 and configuration-2 of model variant as used in Experiment-2. 

\subsection{Experiment-5: Effect of Corpus size} \label{exp-5}

In order to investigate the effect of corpus size and determine the scaling capability of the model, we used extended corpus-90582 (see section \ref{corpora}) for this experiment. As this corpus also contains $12\%$ of ambiguous sentences which impedes the learning and generalization of the model, this experiment will also validate the model's ability to process the abmbiguous sentences. Thus, in order to study the scaling capabilty of the model with different corpus size, 6 sub-corpora were created by randomly sampling $6\%$, $12\%$, $25\%$, $50\%$, $75\%$, $100\%$ of sentences from the orginal corpus of 90582 sentences \cite{xavier:2013:RT}.

\paragraph{Word2Vec-ESN model:} Each of the generated sub-corpora was exposed to the model and a 2-fold cross validation was performed where the model was trained on half the sub-corpora size and tested on remaining half. The second half used for testing was then used to train the model and tested on the first half, used for training previously. This experiment was only performed with Word2Vec-ESN model in both the learning modes i.e. SCL and SFL mode, using a 5 model instances each with a reservoir of 5000 neurons. All other parameter were kept identical to the Experiment-2. 

\subsection{Experiment-6: Generalization on new corpus} \label{exp-6}

One may argue that the previously used corpus (corpus-462 and corpus-90k), which were artifically constructed using grammer is adding a bias to the model which can may make it easier for the model to learn and generalize on these corpora for thematic role assignment task. To answer this question, in this experiment we used the corpus-373 (see section \ref{corpora}) collected in a Human Robot Interaction (HRI) study of language acquisition. 

\paragraph{Word2Vec-ESN model:} To test the generalization of Word2Vec-ESN model on corpus-373, simulations were performed using 10 model instances, in SCL mode and with leave-one-out (LoO) cross validation method. We chose SCL mode and LoO cross-validation method, so that results can be compared with that of obtained using $\theta RARes$ model \cite{tra:xavier_hri}. Also, to make the results of both the model deterministically comparable, topologically modified coding was not used in this experiment. For this experiment, reservoir parameter space was not explored to identify optimal reservoir parameters, but instead, used the optimized parameters obtained on corpus-462 and used in Experiment-2 i.e. $SR = 2.4$, $IS = 2.5$ and $LR = 0.07$. Doing so will enable us to test the robustness of the model parameters, learned previously using corpus-462 with topological modified coded meaning, on the new corpora.

\subsection{Experiment-7: Effect of Word2Vec word dimensions} \label{exp-6}

In all the previous experiments, we used the word vectors of 50 dimensions. However, Mikolov et al. \cite{w2v:mikolov_2013_efficient, w2v:mikolov_2013_distributed} showed that the word vectors of higher dimensions (e.g. 300 in their case) performs better on word analogy task. Thus in this experiment, the effect of different dimensional word vectors on TRA task will be explored. This experiment was only performed on Word2Vec-ESN language model and not on its variant.

\paragraph{Word2Vec-ESN model:} 

Recall that in section \ref{get_word_embeddings}, 6 Word2Vec model were trained each to generate the word vectors of 20, 30, 50, 100, 200, 300 dimensions respectively. Thus, each of these models were used in Word2Vec-ESN language model to test for the effect of respective word vector dimensions. For this experiment, the corpus-373 without the topologically modified coded meaning was used (see fig. \ref{fig:model_variant_1}). Simulations were performed with 10 model instances each with a reservoir of 1000 neurons. The model was trained and tested using LoO cross-validation approach in both the SCL and SFL mode. All the reservoir parameters were kept identical to Experiment-2.
