\BOOKMARK [0][]{chapter.1}{1 Introduction}{}% 1
\BOOKMARK [1][-]{section.1.1}{1.1 Previous Work}{chapter.1}% 2
\BOOKMARK [1][-]{section.1.2}{1.2 Motivation and Hypothesis}{chapter.1}% 3
\BOOKMARK [1][-]{section.1.3}{1.3 Proposed Models}{chapter.1}% 4
\BOOKMARK [1][-]{section.1.4}{1.4 Scope of work}{chapter.1}% 5
\BOOKMARK [1][-]{section.1.5}{1.5 Outline}{chapter.1}% 6
\BOOKMARK [0][]{chapter.2}{2 Basics of Word2Vec and Echo State Network}{}% 7
\BOOKMARK [1][-]{section.2.1}{2.1 Word2Vec}{chapter.2}% 8
\BOOKMARK [2][-]{subsection.2.1.1}{2.1.1 CBOW Model}{section.2.1}% 9
\BOOKMARK [2][-]{subsection.2.1.2}{2.1.2 Skip-gram Model}{section.2.1}% 10
\BOOKMARK [2][-]{subsection.2.1.3}{2.1.3 Properties of Word2Vec embeddings}{section.2.1}% 11
\BOOKMARK [1][-]{section.2.2}{2.2 Echo State Network \(ESN\)}{chapter.2}% 12
\BOOKMARK [2][-]{subsection.2.2.1}{2.2.1 ESN Architecture}{section.2.2}% 13
\BOOKMARK [2][-]{subsection.2.2.2}{2.2.2 Training ESN}{section.2.2}% 14
\BOOKMARK [0][]{chapter.3}{3 Related Work and Open Issues}{}% 15
\BOOKMARK [1][-]{section.3.1}{3.1 Overview of RARes Model}{chapter.3}% 16
\BOOKMARK [2][-]{subsection.3.1.1}{3.1.1 Limitation of RARes model }{section.3.1}% 17
\BOOKMARK [2][-]{subsection.3.1.2}{3.1.2 Research Hypothesis}{section.3.1}% 18
\BOOKMARK [0][]{chapter.4}{4 Approaching Word2Vec-ESN Language Model}{}% 19
\BOOKMARK [1][-]{section.4.1}{4.1 Word2Vec-ESN Language Model}{chapter.4}% 20
\BOOKMARK [2][-]{subsection.4.1.1}{4.1.1 Model initialization}{section.4.1}% 21
\BOOKMARK [2][-]{subsection.4.1.2}{4.1.2 Training model}{section.4.1}% 22
\BOOKMARK [2][-]{subsection.4.1.3}{4.1.3 Evaluation Metrics}{section.4.1}% 23
\BOOKMARK [1][-]{section.4.2}{4.2 Variant of Word2Vec-ESN Model }{chapter.4}% 24
\BOOKMARK [2][-]{subsection.4.2.1}{4.2.1 Training model variant}{section.4.2}% 25
\BOOKMARK [2][-]{subsection.4.2.2}{4.2.2 Decoding Output}{section.4.2}% 26
\BOOKMARK [2][-]{subsection.4.2.3}{4.2.3 Evaluation Metrics}{section.4.2}% 27
\BOOKMARK [1][-]{section.4.3}{4.3 Dataset and pre-processing}{chapter.4}% 28
\BOOKMARK [2][-]{subsection.4.3.1}{4.3.1 Corpus For TRA Task}{section.4.3}% 29
\BOOKMARK [2][-]{subsection.4.3.2}{4.3.2 Corpus For Training Word2Vec Model}{section.4.3}% 30
\BOOKMARK [1][-]{section.4.4}{4.4 Obtaining Word Embeddings}{chapter.4}% 31
\BOOKMARK [0][]{chapter.5}{5 Experiments and Results}{}% 32
\BOOKMARK [1][-]{section.5.1}{5.1 Input and Ouput Coding}{chapter.5}% 33
\BOOKMARK [1][-]{section.5.2}{5.2 Experiments}{chapter.5}% 34
\BOOKMARK [2][-]{subsection.5.2.1}{5.2.1 Experiment-1: Learning thematic roles}{section.5.2}% 35
\BOOKMARK [2][-]{subsection.5.2.2}{5.2.2 Experiment-2: Generalization Capabilities}{section.5.2}% 36
\BOOKMARK [2][-]{subsection.5.2.3}{5.2.3 Experiment-3: Effect of Corpus structure}{section.5.2}% 37
\BOOKMARK [2][-]{subsection.5.2.4}{5.2.4 Experiment-4: Effect of Reservoir size}{section.5.2}% 38
\BOOKMARK [2][-]{subsection.5.2.5}{5.2.5 Experiment-5: Effect of Corpus size}{section.5.2}% 39
\BOOKMARK [2][-]{subsection.5.2.6}{5.2.6 Experiment-6: Neural output activity of the model}{section.5.2}% 40
\BOOKMARK [2][-]{subsection.5.2.7}{5.2.7 Experiment-7: Generalization on new corpus}{section.5.2}% 41
\BOOKMARK [0][]{chapter.6}{6 Conclusion And Future Work}{}% 42
\BOOKMARK [1][-]{section.6.1}{6.1 Conclusion}{chapter.6}% 43
\BOOKMARK [1][-]{section.6.2}{6.2 Future Work}{chapter.6}% 44
\BOOKMARK [0][]{appendix.A}{A Nomenclature}{}% 45
\BOOKMARK [0][]{appendix.B}{B Additional Proofs}{}% 46
\BOOKMARK [0][]{appendix.C}{C Complete Simulation Results}{}% 47
\BOOKMARK [0][]{appendix.C}{Bibliography}{}% 48
